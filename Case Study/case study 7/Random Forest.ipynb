{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "747e7126",
   "metadata": {},
   "source": [
    "## Tree-Based Methods for Regression and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb1db01",
   "metadata": {},
   "source": [
    "Random forest is a powerful method for regression and classification. We will next cover the conceptual foundations of random forests, but we need to start from a simpler method first. These simpler methods are called tree-based methods.\n",
    "\n",
    "The random forest method makes use of several trees when making its prediction, and since in graph theory, a collection of trees is called a forest, this is where the random forest method gets its name.\n",
    "\n",
    "In other words, to make a prediction, the random forest considers the predictions of several trees. It would not, however, be useful to have many identical trees because all these trees would presumably give you the same prediction.\n",
    "This is why the trees in the forest are randomized in a way we'll come back to shortly.\n",
    "\n",
    "Tree-based methods can be used for regression and classification. These methods involve dividing the predictor space\n",
    "into simpler regions using straight lines. So we first take the entire predictor space and divide it into two regions.\n",
    "We now in turn look at each of these two smaller regions, divide them into yet smaller regions, and so on, continuing until we hit some stopping criteria.\n",
    "\n",
    "So the way we divide the predictor space into smaller regions is recursive in nature. To make a prediction for a previously unseen test observation, we find the region of the predictor space where the test observation falls. In the regression setting, we return the mean of the outcomes of the training observations in that particular region,\n",
    "whereas in a classification setting we return the mode, the most common element of the outcomes of the training\n",
    "observations in that region.\n",
    "\n",
    "When we use lines to divide the predictor space into regions, these lines must be aligned with the directions\n",
    "of the axes of the predictor space. And because of this constraint, we can summarize the splitting rules\n",
    "in a tree. This is also why these methods are known as decision tree methods.\n",
    "\n",
    "In higher dimensions, these lines become planes, so we end up dividing the predictor space into high-dimensional rectangles or boxes.\n",
    "\n",
    "How do we decide where to make these cuts? The basic idea is that we'd like to carve out regions in the predictor space that are maximally homogeneous in terms of their outcomes. Remember, we'll ultimately use the mean or the mode\n",
    "of the outcomes falling in a given region as our predicted outcome for an unseen observation. So we can minimize error by finding maximally homogeneous regions in the predictor space.\n",
    "\n",
    "Whenever we make a split, we consider all predictors from $x_1$ to $x_p$, and for each predictor, we consider all possible cut points. We choose the predictor - cut point combination such that the resulting division of the predictor space has the lowest value of some criterion, usually called a loss function, that we're trying to minimize.\n",
    "\n",
    "In regression, this loss function is usually RSS, the residual sum of squares. In classification, two measures are commonly used, called the Gini index and the cross-entropy. You can find their definitions online, but the basic idea\n",
    "is, again, to make cuts using a predictor cut point combination that makes the classes within each region as homogeneous as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85708817",
   "metadata": {},
   "source": [
    "## Random Forest Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1e00ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "707e63f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d5739c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
